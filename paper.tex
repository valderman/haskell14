%-----------------------------------------------------------------------------
%
%               Template for sigplanconf LaTeX Class
%
% Name:         sigplanconf-template.tex
%
% Purpose:      A template for sigplanconf.cls, which is a LaTeX 2e class
%               file for SIGPLAN conference proceedings.
%
% Guide:        Refer to "Author's Guide to the ACM SIGPLAN Class,"
%               sigplanconf-guide.pdf
%
% Author:       Paul C. Anagnostopoulos
%               Windfall Software
%               978 371-2316
%               paul@windfall.com
%
% Created:      15 February 2005
%
%-----------------------------------------------------------------------------


\documentclass[preprint]{sigplanconf}

% The following \documentclass options may be useful:

% preprint      Remove this option only once the paper is in final form.
% 10pt          To set in 10-point type instead of 9-point.
% 11pt          To set in 11-point type instead of 9-point.
% authoryear    To obtain author/year citation style instead of numeric.

\usepackage{amsmath}
\input{macros}

\begin{document}

\special{papersize=8.5in,11in}
\setlength{\pdfpageheight}{\paperheight}
\setlength{\pdfpagewidth}{\paperwidth}

\conferenceinfo{ICFP '14}{Month d--d, 20yy, City, ST, Country} 
\copyrightyear{20yy} 
\copyrightdata{978-1-nnnn-nnnn-n/yy/mm} 
\doi{nnnnnnn.nnnnnnn}

% Uncomment one of the following two, if you are not going for the 
% traditional copyright transfer agreement.

%\exclusivelicense                % ACM gets exclusive license to publish, 
                                  % you retain copyright

%\permissiontopublish             % ACM gets nonexclusive license to publish
                                  % (paid open-access papers, 
                                  % short abstracts)

\titlebanner{banner above paper title}        % These are ignored unless
\preprintfooter{short description of paper}   % 'preprint' option specified.

\title{Type-Safe Client-Server Communication in Web Applications}
\subtitle{Subtitle Text, if any}

\authorinfo{Koen Claessen and Anton Ekblad}
           {Chalmers University of Technology}
           {\{koen,antonek\}@chalmers.se}

\maketitle

\begin{abstract}
This is the text of the abstract.
\end{abstract}

\category{CR-number}{subcategory}{third-level}

% general terms are not compulsory anymore, 
% you may leave them out
%\terms
%term1, term2
%
\keywords
web

\section{Introduction}

Development of web applications is no task for the faint of heart.
The conventional method involves splitting your program into two logical parts,
writing the one in Javascript, which is notorious even among its proponents for
being wonky and error-prone, and the other in the current language du jour.
Then, two are glued together using whichever home-grown network protocol seems
to fit the application. However, most web applications are conceptually
monolithic entities, making this forced split an undesirable hindrance which
introduces new possibilities for defects, adds development overhead and
prevents code reuse.

Several attempts have been made at tackling this problem, but none is, in our
view, satisfactory. In this paper, we propose a programming model in which a
web application is written as a single program from which client and server
binaries are generated during compilation. Type annotations in the source
program control which parts are executed on the server and which are executed
on the client, and the two communicate using type safe RPC calls. Functions
which are not explicitly declared as server-side or client-side are usable by
either side. Our solution is implemented as a Haskell library requiring minimal
to no compiler support, ensuring portability and modularity.

\paragraph{Motivation}

Code written in Javascript, the only widely supported language for client-side
web applications, is often confusing and error-prone, much due to the
language's lack of modularity, encapsulation facilities and type safety.

Worse, most web applications, being intended to facilitate communication, data
storage and other tasks involving some centralized resource, also require a
significant server component. This component is usually implemented as a
completely separate program, and communicates with the client code over some
network protocol.

Having your application rely on some network protocol for
its internal functionality involves writing a lot of boilerplate network code
and some serious advance planning of your application's features to be able to
design a suitable protocol, hampering incremental development. Were we to
discount this initial design burden, ensuring that the protocol is used
correctly throughout the code base as the application evolves and gains new
features would still put an ever increasing burden on the developer.

This state of things is not a concious design choice - most web applications
are conceptually a single entity, not two programs which just happen to talk
to each other over a network - but a consequence of there being a large,
distributed network between the client and server parts.
However, such implementation details should not be allowed to dictate the way
we structure and reason about our applications - clearly, an abstraction is
called for.

To put make all a bit more concrete, let's take a look at an example. Let's say
what we want to implement a simple ``chatbox'' component for a website, to allow
visitors to discuss the site's content in real time. Using mainstream
development practives and recent technologies such as WebSockets, we may come
up with something like the program in figure \ref{lst:javascript-client}.

\begin{listingfloat}
\begin{code}
function handshake(sock) {sock.send('helo');}
function chat(sock, msg) {sock.send('text' + msg);}

window.onload = function() {
  var logbox = document.getElementById('log');
  var msgbox = document.getElementById('message');
  var sock = new WebSocket('ws://example.com:24601');

  sock.onmessage = function(e) {
    logbox.value = e.data + NEWLINE + logbox.value;
  };

  sock.onopen = function(e) {
    handshake(sock);
    msgbox.addEventListener('keydown', function(e) {
      if(e.keyCode == 13) {
        var msg = msgbox.value;
        msgbox.value = '';
        chat(msg);
      }
    });
  };
};
\end{code}
\caption{Javascript chatbox implementation}
\label{lst:javascript-client}
\end{listingfloat}

Since the ``chatbox'' application is very simple - users should only be able to
send and receive text messages in real time - we opt for a very simple
design. Two UI elements, \lstinline!logbox! and \lstinline!msgbox!, represent
the chat log and the text area where the user inputs their messages
respectively. When a message arrives, it is prepended to the chat log, making
the most recent message appear at the of the log window, and when the user hits
the return key in the input text box the message contained therein is sent and
the input text box is cleared.

Messages are transmitted as strings, with the initial four characters
indicating the type of the message and the rest being the optional payload.
There are only two messages; a handshake indicating that a user wants to join
the conversation, and a broadcast message which sends a line of text to all
connected users via the server.

This code looks solid enough by web standards, but even this simple piece of
code contains no less than three asynchronous callbacks, two of which both read
and and modify the application's global state. This makes the program flow
non-obvious, and introduces unnecessary risk and complexity through the
haphazard state modifications.

Moreover, this code is not very extensible. If this simple application is to be
enhanced with new features down the road, the network protocol will clearly
need to be redesigned. However, if we were developing this application for a
client, said client would likely not want to pay the added cost for the design
and implementation of features she did not ask for, and perhaps never will.

Should the protocol need updating in the future, how much time will we need to
spend on ensuring that the protocol is used properly across our entire program,
and how much extra work will it take to keep the client and server in sync?
How much code will need to be written twice, once for the client and once for
the server, due to the unfortunate fact that the two parts are implemented as
separate programs, possibly in separate languages?

Above all, is it really necessary for such a simple program to involve
client/server architectures and network protocol design at all?

\section{A seamless programming model}
\section{Implementation}
\section{The Haste compiler}

In order to allow the same language to be used on both client and server, we
obviously need some way to compile that language into Javascript. To this end,
we make use of the Haste compiler\ \cite{haste}, developed as a MSc thesis and
extended as part of this work. Haste builds on the GHC compiler to provide
the full Haskell language, including most GHC-specific extensions, in the
browser.

\paragraph{Choosing a compiler} Haste is by no means the only
Javascript-targeting compiler for a purely functional language. In particular,
the GHC-based GHCJS\ \cite{ghcjs} and UHC\ \cite{uhc} compilers are both
capable of compiling standard Haskell into Javascript; the Fay\ \cite{fay}
language was designed from the ground up to target the web space using a subset
of Haskell; and there exist solutions for compiling Erlang\ \cite{jserlang} and
Clean\ \cite{jsclean} to Javascript as well.

In the face of this multitude of options, why did we settle on Haste? We make
the following demands of a candidate source language:

\begin{itemize}
  \item The language must provide a static type system, since one of our
        primary concerns is to reduce defect rates through static typing of
        the client-server communication channel.
  \item The language must be compilable to both Javascript and a format
        suitable for server-side execution as we want our web applications
        to be written as a single, monolithic program.
  \item We also want our language to be practical, in the sense that its output
        should not be disproportionately large or slow. This is more important
        for the client part, where we have to contend with slow connections and
        the overhead of running within an interpreter, than for the server part.
\end{itemize}

Our first criterion rules out the dynamically typed Erlang. The second rules
out Fay which unfortunately lacks critical Haskell features, most notably type
classes.

This still leaves us with four options: Clean, GHCJS, Haste and UHC. However,
the output from GHCJS is prohibitively large - often in the range of several
megabytes for very simple programs - which rules it out for our use case, in
spite of providing slightly better compatibility with low-level GHC features
than Haste. Similarly, the code produced by the UHC Javascript backend tends to
be relatively slow due to it lacking the more mature optimization capabilities
of GHC, as well as being in the same ballpark as GHCJS for size.\ \cite{haste}

This leaves us choosing between Clean and Haste for our client compiler. Since
most of our abstractions, both the cooperative multitasking and the type-safe
client-server communication itself, are easily expressed as monads, well
supported in Haskell thanks to do-notation, the choice fell to Haste.

\paragraph{Design of the Haste compiler} Haste is first and foremost intended
to be a practical compiler; the ability to produce code which is lean and fast
enough to be used in the real world is critical. To this end, we make several
design choices and tradeoffs, some of which would be viewed as detrimental in a
more purist context.

One such tradeoff is the decision to make use of the facilities provided by the
web browser - most prominently the Javascript engine's native garbage
collector - as far as possible rather than implementing parts of the GHC
runtime in Javascript. In the same vein, a conscious effort is made to generate
as ``regular-looking'' code as possible. In some rare cases, this means having
to sacrifice compatibility with low-level GHC features. Most notably, Haste
does not support weak references or pre-emptive multitasking, as these would
require modifications to the runtime system and generated code which confound
the structure of the resulting Javascript and have a detrimental impact on code
size and execution speed.

GHCJS takes the opposite view, that faithful emulation of the GHC runtime is
paramount. Of course, this brings an impressive degree of compatibility, at the
cost of the blowup in code size mentioned previously.

\paragraph{Implementation} As previously mentioned, Haste offloads much of the
heavy lifting of compilation - parsing, type checking, intermediate code
generation and many optimizations - onto GHC, and takes over code generation
after the STG generation step, at the very end of the compilation process.
STG\ \cite{stg} is the last intermediate representation used by GHC before
the final code generation takes place and has several benefits for use as
Haste's target language:

\begin{itemize}
  \item STG is still a functional intermediate representation, based on the
        lambda calculus. When generating code for a high level target language
        such as Javascript, where functions are first class objects, this
        allows for a higher level translation than when doing traditional
        compilation to lower level targets like stack machines or register
        machines. This in turn allows us to make more efficient use of the
        target language's runtime, leading to smaller, faster code.
  \item In contrast to Haskell itself and GHC's intermediate Core language, STG
        represents `thunks`, the construct used by GHC to implement non-strict
        evaluation, as closures which are explicitly created and evaluated.
        Closures are decorated with a wealth of information, such as their set
        of captured varibles, any type information needed for code generation,
        and so on. While extracting this information manually is not very hard,
        having this done for us means we can get away with a simpler
        compilation pipeline.
  \item The language is very small, essentially only comprising lambda
        abstraction and application, plus primitive operations and facilities
        for calling out to other languages. Again, this allows the Haste
        compiler to be a very simple thing indeed.
  \item Any extensions to the Haskell language implemented by GHC will already
        have been translated into this very simple intermediate format,
        allowing us to support basically any extension GHC supports without
        effort.
  \item Application of external functions is always saturated, as is
        application of most other functions. This allows for compiling most
        function applications into simple Javascript function calls, limiting
        the use of the slower dynamic techniques required to handle curried
        functions in the general case\ \cite{fastcurry} to cases where it is
        simply not possible to statically determine the arity of a function.
\end{itemize}

In light of its heavy reliance on STG, it may be more correct to categorize
Haste as an STG compiler rather than a Haskell compiler.

The runtime data representation of Haste programs is kept as close to regular
Javascript programs as possible. The numeric types are represented using the
Javascript \lstinline!Number! type, which is defined as the IEEE754 double
precision floating point type. This obviously adds some overhead to operations
on integers as overflow and non-integer divisions must be handled. However, this
is common practice in hand-written Javascript as well, and is generally handled
efficiently by Javascript engines.

Values of non-primitive data types in Haskell consist of a data constructor and
zero or more arguments. In Haste, these values are represented using arrays,
with the first element representing the data constructor and the following
values representing its arguments. For instance, the value \lstinline!42 :: Int!
is represented as \lstinline![0, 42]!, the leading \lstinline!0! representing
the zeroth constructor of the \lstinline!Int! type and the \lstinline!42!,
obviously, representing the ``machine'' integer. It may seem strange that a
limited precision integer is represented using one level of indirection rather
than as a simple number, but recall that the \lstinline!Int! type is defined by
GHC as \lstinline!data Int = I# Int#!.

Functions are represented as plain Javascript functions, one of the blessings
of targeting a high level language, and application is can therefore be
implemented as its Javascript counterpart in most cases. In the general case,
however, functions may be curried. For such cases where the arity of an applied
function can not be determined statically, application is implemented using the
eval/apply method described in \cite{fastcurry} instead.

\paragraph{Interfacing with Javascript} While Haste supports the Foreign
Function Interface inherited from GHC, with its usual features and limitations
\ \cite{ffi}, it is often impractical to work within the confines of an
interface designed for communication on a very low level. For this reason
Haste sports its own method for interacting with Javascript as well, which
allows the programmer to pass any value back and forth between Haskell and
Javascript, as long as she can come up with a way to translate this value
between its Haskell and Javascript representations. Of course, not performing
any translation at all is also a valid ``translation'', which allows Haskell
code to store any Javascript value for later retrieval without inspecting it
and vice versa. The following example implements mutable variables using this
custom Javascript interface.

\begin{code}
import Haste.Foreign

-- A MutableVar is completely opaque to Haskell code
-- and is only ever manipulated in Javascript. Thus,
-- we use the Unpacked type to represent it,
-- indicating a completely opaque value.
newtype MutableVar a = MV Unpacked

instance Marshal (MutableVar a) where
  pack          = MV
  unpack (MV x) = x

newMutable :: Marshal a => a -> IO (MutableVar a)
newMutable = ffi "(function(x) {return {val: x};})"

setMutable :: Marshal a => MutableVar a -> a -> IO ()
setMutable = ffi "(function(m, x) {m.val = x;})"

getMutable :: Marshal a => MutableVar a -> IO a
getMutable = ffi "(function(m) {return m.val;})"
\end{code}

The core of this interface consists of the \lstinline!ffi! function, which
allows the programmer to create a Haskell function from arbitrary Javascript
code. This function exploits Javascript's ability to parse and execute
arbitrary strings at run-time using the \lstinline!eval! function, coupled with
the fact that functions in Haste and in Javascript share the same
representation, to dynamically create a function object at runtime.
The \lstinline!ffi! function is typed using a well-known type class trick for
creating statically typed variadic functions\ \cite{printf}, and works very
much like the \lstinline!printf! function of Haskell's standard library.
When applied to one or more arguments instantiating the \lstinline!Marshal!
type class, the \lstinline!pack! function is applied to each argument,
marshalling them into their respective Javascript representations, before they
are passed to the dynamically created function. When that function returns,
the inverse \lstinline!unpack! function is applied to its return value before
it is passed back into Haskell land.

As the marshalling functions chosen for each argument and the foreign
function's return value depends on its type, the programmer must explicitly
specify the type of each function imported using \lstinline!ffi!; in this,
Haste's custom method is no different from the conventional FFI.

There are several benefits to this method, the most obvious being that new
marshallable types can be added by simply instantiating a type class. Thanks
to the lazy evaluation employed by Haste, each foreign function object is only
created once and then cached; any further calls to the same (Haskell) function
will reuse the cached function object. Implementation-wise, this method is also
very non-intrusive, requiring only the use of the normal FFI to import
Javascript's \lstinline!eval! function; no modification of the compiler is
needed.

\section{Discussion and related work}

Other approaches to this problem exist, notably in the form of the
Conductance\ \cite{conductance}, Duetto\ \cite{duetto} and
Sunroof\ \cite{sunroof} projects, all of which implement some synchronous
abstraction over the network between the client and the server, much like our
solution.

\paragraph{Conductance} Conductance is an application server built on
StratifiedJS, a Javascript language extension which adds a few niceties such as
cooperative multitasking and more concise syntax for many common tasks.
Conductance uses an RPC-based model for client-server communication, much like
our own, but also adds the possibility for the server to independently transmit
data back to the client through the use of shared variables or call back into
the client by way of function objects received via RPC call, as well as the
possibility for both client and server to seamlessly modify variables located
on the opposite end of the network.

While Conductance gets rid of the callback-based programming model endemic to
regular Javascript, it still suffers from many of its usual drawbacks. In
particular, the weak typing of Javascript poses a problem in that the
programmer is in no way reprimanded by her tools for using server APIs
incorrectly or trying to transmit values which can not be sensibly serialized
and de-serialized, such as DOM nodes. Wrongly typed programs will thus crash, or
even worse, gleefully keep running with erroneous state due to implicit type
conversions, rather than give the programmer some advance warning that something
is amiss.

We are also not completely convinced that the ability to implicitly pass data
back and forth over the network is a unilaterally good thing; while this indeed
provides the programmer some extra convenience, it also requires the programmer
to exercise extra caution to avoid inadvertently sending large amounts of data
over the network.

\paragraph{Duetto} Duetto is a C++ compiler targeting the web, written from
the ground up to produce code for both client and server simultaneously. It
utilizes the new attributes mechanism introduced in C++11 to designate
functions and data to live on either client or server side. Any calls to a
function on the other side of the network and attempts to access remote data
are implicit, requiring no extra annotations or scaffolding at the call site.

Much like Conductance, Duetto suffers somewhat from its heritage: while the
client-side code is not memory-unsafe, as it is not possible to generate
memory-unsafe Javascript code, its server-side counterpart unfortunately is.
Our reservations expressed about how network communication in Duetto can be
initiated implicitly apply to Duetto as well.

\paragraph{Sunroof} In contrast to the Conductance and Duetto, Sunroof is an
embedded language. Implemented as a Haskell library, it allows the programmer
to use Haskell to write code which is compiled to Javascript and executed on
the client. The language can best be described as having Javascript semantics
with Haskell's type system. Communication between client and server is
accomplished through the use of ``downlinks'' and ``uplinks'', allowing for
data to be sent to and from the client respectively.

Sunroof is completely type-safe, in the DSL itself as well as in the
communication with the Haskell host. However, the fact that client and server
must be written in two separate languages - any code used to generate
Javascript must of course be built solely from the primitives of the Sunroof
language, precluding use of general Haskell code - makes code reuse hard.

\paragraph{Advantages to our approach} We believe that our approach has a
number of distinct advantages to the aforementioned attacks on the problem.

Our approach gives the programmer access to the same strongly typed,
general-purpose functional language on both client and server; any code which
may be of use to both client and server is effortlessly shared, leading to less
duplication of code and increased possibilities for reusing third party
libraries.

Any and all communication between client and server is both strongly typed
and made explicit by the use of the \lstinline!onServer! function, with the
programmer having complete control over the serialization and de-serialization
of data using the appropriate type classes. Aside from the obvious advantages
of type safety, making the crossing of the network boundary explicit helps the
programmer make an informed decision as to when and where server communication
is appropriate.

Our programming model is implemented as a library, assuming only two Haskell
compilers, one targeting Javascript and one targeting the programmer's server
platform of choice. While we use Haste as our Javascript-targeting compiler,
modifying our implementation to use GHCJS or even the Javascript backend of UHC
would be entirely straightforward. This implementation not only allows for
greater flexibility, but also eliminates any potentially hairy interaction with
compiler internals.

\paragraph{Limitations} Unlike any of the related works, our approach takes a
firm stand, regarding the client as the driver in the client-server
relationship with the server taking on the role of a passive computational
or storage resource. The server may thus not call back into the client at
arbitrary points but is instead limited to returning answers to client-side
queries. This is clearly less flexible than the back-and-forth model of Sunroof
and Duetto or the shared variables of Conductance. However, we believe that
this restriction makes program flow easier to follow and comprehend. Like the
immutability of Haskell, this model gives programmers a not-so-subtle hint
as to how they may want to structure their programs. Should this model prove
insufficiently expressive, extending our existing model with an
\lstinline!onClient! counterpart to \lstinline!onServer! would be relatively
straightforward.

While our solution completely safe from the invocation point of the
\lstinline!runApp! function onward, capturing IO-dependent variables introduced
before this invocation may lead to the client and server execution paths
diverging. Consider the following example:

\begin{code}
main = do
  captured <- randomRIO (False, True)

  runApp config $ do
    diverged <- export $ \transmitted -> do
      if captured == transmitted
        then return ``All OK''
        else return ``Diverged''

    runClient $ do
      divergence <- onServer (diverged <.> captured)
      alert divergence
\end{code}

The dialog box displayed by this program will read ``All OK'' roughly half
of the times it is run, while in half of the runs it will read ``Diverged''.
The reason for this is that the \lstinline!randomRIO! computation will be
executed twice - once on the client, and once on the server. Whenever the
computation returns differening results, the client and the server will have
conflicting opinions on the actual value of \lstinline!captured!, causing any
code which - quite reasonably - assumes that variables are consistent between
client and server to fail.

This is easily remedied however, by a slight compiler modification. Instead of
using \lstinline!main :: IO ()! as the program entry point, introduce a function
\lstinline!appMain :: App Done! for this purpose, and let the runtime system
start the application by invoking \lstinline!runApp config appMain!, where
\lstinline!config! contains the URL and port configuration for the server, given
by the programmer using a compiler flag. As this modification only affects the
program's entry point, which is already given ``special'' treatment in Haskell
compilers, we believe this to be a practical, non-intrusive way to remove this
limitation, and in fact made this modification to the Haste compiler for our
implementation.

The astute reader may notice that the same applies to code using
\lstinline!unsafePerformIO! to declare IO-dependent top-level values, and that
this problem is unaffected by changing the type of the program's entry point.
While this is indeed true, we feel that since it is quite possible to break
any Haskell program using \lstinline!unsafePerformIO!, even subverting the type
system, this is not a problem with our solution.

\section{Future work}

\paragraph{Information flow control} Web applications often make use of a wide
range of third party code for user tracking, advertising, collecition of
statistics and a wide range of other tasks. Any piece of code executing in the
context of a particular web session may not only interact with any other piece
of code executing in the same context, but may also perform basically limitless
communication with third parties and may thus, inadvertently or not, leak
information about the application state. This is obviously highly undesirable
for many applications, which is why there is ongoing work in controlling the
information flow within web applications\ \cite{jsflow}.

While this would indeed provide an effective defence towards attackers and
programming mistakes alike, there is value in being able to tell the two apart,
as well as in catching policy violations resulting from programming mistakes
as early as possible. An interesting venue of research would be to investigate
whether we can take advantage of our strong typing to generate security policies
for such an information flow control scheme, as well as ensure that this policy
is not violated at compile time. This could shorten development cycles as well
as give a reasonable level of confidence that any run time policy violation is
indeed an attempted attack.

\paragraph{Reactive client-server GUI toolkit} While we believe that our work
represents a step forward in making web applications more robust and easier to
develop, the basic model for updating the application's user-visible state is
still essentially imperative. Implementing an FRP-style\ \cite{ppfrp} GUI
programming model on top of our client-server abstraction may prove a fruitful
way to further improve the programmability of web-based distributed
applications.

\section{Conclusion}

\acks

Acknowledgments, if needed.

% We recommend abbrvnat bibliography style.

\bibliographystyle{abbrvnat}

% The bibliography should be embedded for final submission.

\begin{thebibliography}{}
\softraggedright

\bibitem[Bracker, Gill (2014)]{sunroof}
J. Bracker and A. Gill: Sunroof: A monadic DSL for generating JavaScript, Practical Aspects of Declarative Languages, 65-80, 2014

\bibitem[Conductance application server (2014)]{conductance}
THE INTERNETS: http://conductance.io

\bibitem[Dijkstra et al (2013)]{uhc}
A. Dijkstra, J. Stutterheim, A. Vermeulen, S. D. Swierstra: Building JavaScript applications with Haskell, Implementation and Application of Functional Languages, pp 37-52, 2013

\bibitem[Domoszlai et al (2011)]{jsclean}
L. Domoszlai, E. Bruël, J. M. Jansen: Implementing a non-strict purely functional language in JavaScript, in Acta Universitatis Sapientiae, 2011

\bibitem[Duetto compiler (2014)]{duetto}
THE INTERNETS: http://leaningtech.com/duetto/

\bibitem[Ekblad (2012)]{haste}
A. Ekblad: Towards a declarative web, MSc thesis, University of Gothenburg, 2012

\bibitem[Elliott (2009)]{ppfrp}
C. M. Elliott: Push-pull functional reactive programming, in Proceedings of the 2nd ACM SIGPLAN symposium on Haskell, 2009

\bibitem[The Fay language (2014)]{fay}
THE INTERNETS: http://fay-lang.org

\bibitem[Guthrie (2014)]{jserlang}
G. Guthrie: http://luvv.ie/2014/01/21/your-transpiler-to-javascript-toolbox/, 2014

\bibitem[Hedin et al (2014)]{jsflow}
D. Hedin, A. Birgisson, L. Bello and A. Sabelfeld: JSFlow: Tracking Information Flow in JavaScript and its APIs, 2014

\bibitem[Marlow, Peyton Jones (2004)]{fastcurry}
S. Marlow, S. Peyton Jones: Making a fast curry: push/enter vs. eval/apply for higher order languages, 2004

\bibitem[Nazarov (2012)]{ghcjs}
V. Nazarov: GHCJS Haskell to Javascript Compiler, https://github.com/ghcjs/ghcjs

\bibitem[Peyton Jones (1992)]{stg}
S. Peyton Jones: Implementing lazy functional languages on stock hardware: the Spineless Tagless G-machine, Journal of Functional Programming, 1992

\bibitem[Peyton Jones (2001)]{ffi}
S. Peyton Jones: Tackling the awkward squad: monadic input/output, concurrency, exceptions, and foreign-language calls in Haskell

\bibitem[Taylor (2013)]{printf}
C. Taylor: Polyvariadic Functions and Printf, http://chris-taylor.github.io/blog/2013/03/01/how-haskell-printf-works/, 2013

\end{thebibliography}


\end{document}
